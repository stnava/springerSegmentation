---
title: "Convolutional neural networks for rapid and simultaneous brain extraction and tissue segmentation"
link-citations: yes
output: 
  pdf_document:
    citation_package: natbib
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    template: svm-latex-ms.tex
thanks: "This work was supported by K01 ES025432-01"
author:
- name: Nicholas Cullen
  affiliation: University of Pennsylvania, Philadelphia, PA 19104
- name: Brian B. Avants
  affiliation: University of Pennsylvania, Philadelphia, PA 19104
keywords: "deep learning, segmentation, convolutional, brain, neuroimaging"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
bibliography: dlSeg.bib
biblio-style: plain
---

# Abstract

Convolutional neural networks are poised to become a standard technology in neuroimage analysis.  This general purpose framework is capable of integrating imaging information across both spatial scales and modalities acquired from biomedical images.  Furthermore, emerging deep learning software is designed for processing large datasets efficiently.  Complemented with the ability to fuse imaging and non-imaging data, these features make deep learning and convolutional networks an integral tool in the future of brain mapping.  Here, we discuss both the context and technology of deep learning and detail the issues of problem definition, network design and evaluation that neuroimaging researchers may encounter.  We will focus primarily on applying convolutional-deconvolutional networks to supervised brain segmentation and provide a comparison with joint label fusion, another state of the art method addressing this problem.

# Introduction

### What is biomedical image segmentation and why is it valuable?

Biomedical segmentation annotates raw data with structural or functional context allowing the data to be interpreted statistically and in specific scientific terms.  In the human brain, this may involve very high-resolution labeling of neurons [@FIXME], classification of primary tissue classes from magnetic resonance imaging (MRI), a detailed parcellation [@FIXME] of cortical regions [@FIXME] or even fine-grained localization of hippocampal subfields [@FIXME].  While unsupervised segmentation is highly valuable [@FIXME], supervised approaches seek to directly model expert knowledge. Such methods may automatically reproduce the performance of highly-trained neuroanatomists or diagnosticians at both lower cost and with greater consistency and speed.  A supervised algorithm that performs near expert levels of accuracy allows that expert knowledge to be shared via the combination of software and data.  For instance, the collection of cortical parcellations shared in [@FIXME] are used to reproduce accurate labelings in likely millions of new images by combining this labeled data with computational tools. The parcellations also serve as a foundation for several public segmentation challenges [@FIXME], aid interpretation of large and heterogenous datasets [@FIXME] as well as longitudinal changes in Alzheimer's disease [@FIXME].  Similarly, a recent segmentation method, LINDA [@FIXME], was trained on an expert neurologist's annotations of post-stroke lesions in T1-weighted neuroimages and shown to provide comparable performance on unseen datasets from other clinical sites. The model itself is freely available for download and yet does not require the original annotations to be shared. Thus, supervised biomedical segmentation algorithms may be used to store and share rarefied expertise thereby helping to standardize challenging biomedical quantification problems and establish new widely accessible pathways to knowledge [@FIXME; @FIXME].

### Traditional approaches to brain segmentation and parcellation

Constantin von Economo's cytoarchitectonic map, a collaborative 13 year effort, is among the most detailed and influential works in quantitative segmentation [@vonEcon].  The datasets of interest to the majority of practictioners today are at a much coarser scale ( approximately 1 millimeter resolution ) but are collected in diverse populations during life.  This presents the opportunity to perform, for the first time in human history, large studies of brain variability and longitudinal change. The relative novelty and prevalence of these (most commonly MRI) data have driven recent technical research into computer-assisted methods for segmentation and, as such, we will briefly summarize relevant algorithms in this context.

The last two decades of algorithms designed for prior-driven (supervised) brain segmentation fall roughly into *probabilistic*, *multi-atlas* or *machine learning* categories.  The boundaries between these categories are not stark and transition between them also correlates with increasing compute power.  Probabilistic methods, such as those provided by the popular SPM5 package [@FIXME], tend to rely on a single atlas that summarizes population data with spatial probability maps for different anatomical classes.  This era was computationally restricted and waned, more or less, in the second decade of the current millenium.  Around 2010, multi-atlas labeling (MAL) --- which often relies heavily on deformable registration --- emerged as the premier technology for performing brain parcellation in particular when spatial location is highly informative about the class of a given part of the brain [@FIXME].  Rather than averaging expert labels in a common template space before applying to a new brain, MAL propagates the full cohort of labels into each individual image space and performs aggregation within that space.  The best of these methods also incorporate local patch-based similarity between the atlases and the target brain while accounting for redundancy between the atlases [@FIXME].  More recently, machine learning methods have become available that may capture nonlinear and highly multivariate information that may be leveraged to improve segmentation [@FIXME].  Deep learning is in this category and will be discussed below.

For problems such as labeling the hippocampus, moving from a single probabilistic atlas to multiple atlas methods led to a nearly 20\% improvement in performance [@WangSuhDasEtAl2013].  As shown within [@MendrikVinckenKuijfEtAl2015], even traditional 3 tissue segmentation in the brain may be improved upwards of 10\% by adopting more recent algorithms.  In more difficult tissue segmentation problems, such as enhancing brain tumors, moving to machine learning methods resulted in improvements on the order of 25\% or more (compare BRATS 2012 performance to more recent results such as [@MenzeJakabBauerEtAl2015] and [@HavaeiDavyWarde-FarleyEtAl2017]).

Despite these advances, there remains the possibility for further improvement in segmentation, in particular as the size of training and "wild-type" datasets grow which will greatly increase the degree of variability to which algorithms must adapt.  The primary limitation of algorithms based on single probabilistic atlases is that they relied heavily on, for instance, Gaussian mixture models to cutomize the priors to individual datasets.   The limitation for MAL may be similar in that they may be limited by design; most MAL methods use assumptions of locality and linearity.  Newer methods, such as deep learning, have the ability to store --- within their own architecture --- a much greater degree of adaptability and nonlinearity than is available from existing labeled datasets alone.

<!-- FIXME - need graph showing performance gains in linear vs DL models!! -->


### What is deep learning?

Deep learning algorithms link and optimize computational layers in order to build predictive multi-scale data representations.  The design of these general purpose computational machines is inspired by the layered and interconnected cortical columns of the mammalian brain.  An excellent review of the field is available here [@LeCunBengioHinton2015] which describes deep learning as composing multiple simple but non linear modules that, in aggregate, allow very complex functions to be learned.  Some of the more famous examples of deep learning architectures include AlexNet (8 layers), VGG Net (19 layers), GoogLeNet (22 layers) and ResNet (152 layers), all of which pushed the performance envelope in the international ImageNet challenge.  ImageNet winners currently compete with or exceed human performance [@HeZhangRenEtAl2015] on an image-based 1000 class object identification problem, an achievement that is a testament to both decades of prior work as well as the value of public competition, communication and evaluation [@SchoenickClarkTafjordEtAl2016].  

Current limitations of deep learning, in particular within the biomedical domain, include the perceived need for relatively large training datasets and the lack of interpretability.  However, substantial progress is being made on both fronts, i.e. the visualization of deep learning [@MordvintsevOlahTyka2015] as well as practical methods for data augmentation and one-shot learning [@SantoroBartunovBotvinickEtAl2016].  Furthermore, deep learning performance is accelerating with recent substantial investment from industry.  In particular, Google broke new ground in machine translation [@WuSchusterChenEtAl2016] which now approaches human performance in several language pairs. While there are many challenges to broad adoption of this machinery, it is likely that the investments into deep learning infrastructure made by Google, Facebook, Baidu and Microsoft (among others) will only further improve the value of the underlying software [@Goldsborough2016].  It is therefore imperative that more scientific investigators --- brain mappers, in particular --- become not only familiar but also facile with deep learning.  Toward that end, we discuss perhaps the most transparent application for deep learning to a problem that is commonly faced in neuroimaging: tissue segmentation of T1-weighted MRI as in [@TustisonCookKleinEtAl2014].

<!-- see [9 papers in deep learning](https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html).
meaning of deep:  Deep neural networks are neural networks with more than two or three layers.  Truly deep network architectures win the many class ImageNet problem such as Since 201X, deep learning ImageNet results surpass human performance (5.1\%).

"Stacking all of these layers and adding huge numbers of filters has a computational and memory cost, as well as an increased chance of overfitting"
 
Deep learning is commonly applied in large-scale annotation of both images and language. 
In images                 The neural network developed by Krizhevsky, Sutskever, and Hinton in 2012 was the coming out party for CNNs in the computer vision community. This was the first time a model performed so well on a historically difficult ImageNet dataset. Utilizing techniques that are still used today, such as data augmentation and dropout, this paper really illustrated the benefits of CNNs and backed them up with record breaking performance in the competition. In language translation ...
Most famously, Google Translate's latest incarnation relies on deep neural networks and produced a true paradigm shift in terms of performance.    kaggle.

imagine the future: cloud-based databases of labeled data that let us ID patterns in medical images

public resources - what tools are needed for this scenario?

http://www.deeplearningbook.org/

https://github.com/terryum/awesome-deep-learning-papers

https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap

-->

    

### Convolutional networks and brain segmentation

Convolutional neural networks have image-specific layers that consist of patch-like "local modules" that act as a set of spatially varying and interconnected feature representations.  Shallow layers typically learn basic features such as edges, while deeper layers begin to aggregate information into more abstract representations.  In the case of object detection, layers may model the class appearance itself [@LeRanzatoMongaEtAl2011]. This ability to represent nonlinear hierarchical *spatially constrained* information is thought to confer performance advantages over more traditional approaches (even non-convolutional networks.) The winning team for a connectomics challenge employed convolutional networks and "had no prior experience with EM [electron microscopic] images"  [@Arganda-CarrerasTuragaBergerEtAl2015], thus showing the power of convolutional networks in combination with well-curated training data in a supervised learning framework. 

Convolutional networks are prevalent in brain segmentation research [@MoeskopsViergeverMendrikEtAl2016; @ZhangLiDengEtAl2015; @ChoiJin2016; @KorfiatisKlineErickson2016; @HavaeiDavyWarde-FarleyEtAl2017; @XingXieYang2016; @KamnitsasLedigNewcombeEtAl2017] and push performance standards in open challenges such as ISLES and BRATS [@KamnitsasLedigNewcombeEtAl2017]. Specifically, deconvolutional architectures [@ZeilerKrishnanTaylorEtAl2010; @ZeilerFergus2014; @NohHongHan2015] reach or exceed state-of-the-art in image segmentation problems in both computer vision and medical imaging.  Importantly, such networks may not need enormous numbers of labeled individual subjects within training datasets in order to achieve clinically valuable results [@BroschTangYooEtAl2016].  This is due to the fact that most neuroimages are, at several scales, highly redundant. That is, even a single image provides a relatively large sampling of variability in the appearance of local anatomy. Convolutional networks transform this structure into a spatially informed set of weight functions or patterns. By exploiting supervision, these expressive multi-scale patterns are *automatically customized* according to the prediction problem at hand.  Thus, a single architecture can be repurposed for many different prediction problems [@JanowczykMadabhushi2016].\footnote{Here, the AlexNet architecture was repurposed very successfully for digital pathology with only small customization in preprocessing and sampling steps.}

<!-- This, in  part, explains the prominence and successes of patch-based methods in biomedical image processing [@CordierDelingetteAyache2016; @LiuKitschMillerEtAl2016; @KamnitsasLedigNewcombeEtAl2017; @ZhaoWangNiuEtAl2016; @GuoWuCommanderEtAl2014; @MoeskopsViergeverMendrikEtAl2016]. -->

In the remainder of this chapter, we will detail the steps involved in developing a convolutional-deconvolutional network for brain extraction and segmentation.  These steps illustrate the efforts in this particular application's (recent) history but we also reflect on the more general lessons learned in engineering a practical machine learning system.  The typical steps involved in the training and application of convolutional networks to biomedical image segmentation include: (1) *Data curation:* selection of data that is representative of raw data, $\{ x_i \}$, but also annotated with useful evaluation targets, $\{ y_i \}$; (2) *Problem definition:* specific question that can be answered, given the data, and the associated biological and other metrics and/or objective (loss) functions defining the learning problem i.e. $f( x_i ) = y_i$; (3) *Split data:* divide data into train, test and validation sets perhaps with some effort to balance the categories; (4) *Redesign/refine:* improve the proposed system(s) with respect to cross-validation performance; (5) *Validate*: apply the system to held-out data and, crucially, an independent biologically-motivated criterion; (6) *Interpret* the architecture and outcomes.  See Figure 1 for an overview of this system.



FIXME: figure showing system - something like [figure 1 D here](http://msb.embopress.org/content/msb/12/7/878.full.pdf)



# MATERIALS

### Imaging data

We demonstrate our application on the T1-weighted neuroimages collected in the Dallas Lifespan Brain Study (DLBS) available [here](www.google.com) and describe in [@DLBS; @DLBS2].

### Software

Deep learning software is both well documented and highly optimized for both large datasets (via incremental learning) and modern parallel computation (via graphical processing units --- GPUs) in comparison to other machine learning methodologies.  Our preferred framework is *TensorFlow* which is entering its version 1.0 release which will guarantee backward compatibility.  TensorFlow features many of the latest advances in deep learning research as well as the unique (in current software) ability to distribute problems across multiple CPUs or GPUs on a given machine.  In contrast, CAFFE (another leading platform) is currently limited to using a single GPU.  Thus, we recommend TensorFlow as the underlying platform for future deep learning implementations.  TensorFlow is described in ... but check the latest documentation for up to date features.  We access TensorFlow via both Python 2.7 and 3.x in order to guarantee validity across both major versions of Python.

Below, we will compare our convolutional networks with Joint Label Fusion (JLF), an established MAL algorithm [@WangSuhDasEtAl2013]. JLF is available in both ANTs FIXME REF and via R-based wrappers in ANTsR [@R-ANTsR; @HavaeiDavyWarde-FarleyEtAl2017] REF-ANTsR REF-Neuroconductor.  We also employ R [@R-Ref] and ANTsR for basic data organization and early validation efforts.

# METHODS

This is the main section and should explain in detail the individual steps necessary to carry out
the technique. Where possible, please simply list the steps in numerical order. For techniques
that comprise a number of separate major procedures, please indicate these separate
procedures in the introduction, and then subdivide section 3 into subheadings to cover each
procedure (3.1, 3.2 etc; please avoid any further subdivision of these headings). The steps in
each subsection should then be numbered individually, renumbering from number one. Do take
great care to try to indicate any little "tricks" or nuances that help improve your method by
referring to relevant "notes" in section 4 (see below). This sort of information rarely gets into the
scientific literature. You may also find it useful to relate to some aspects of the theory in this
section indicating the purpose of some of the major steps by cross-referencing to an appropriate
“note”. Do not be tempted to get involved in the description of variations/alternatives to your
technique in this section: this can be done in the "Notes" section. Stick to the basic procedure
detailed in this section.

This section must be comprehensive. Do not send the reader away to find information for a
particular step in another reference. All relevant practical detail must be given in this section

### Data curation

### Problem Definition 

Define problem and possible solutions

### Split data

* Divide data into train, test and validate

* unit tests / sanity checks

### Redesign/refine

* Develop the system: the train / test loop

    * preprocessing
    
    * patch or dense

    * network architecture - add nuisance variables?
    
    * type of output: classification, probability, etc.

### Validate

### Interpret

* independent validation 

* biological plausibility 

* may loop back to system step

# NOTES

As we all know, even the simplest techniques go wrong from time to time. Would you therefore
indicate any major problems or faults that can occur with your technique? Try to indicate the
major sources of problems and how they can be identified and overcome. With reference to
related techniques, any variations of the technique that you have described should also be made
in this section, as well as--where relevant--an indication of the sensitivity of the method, timescale
for the singled technique, etc. This "Notes" section is a hallmark of this series and has been
singled out for praise by a number of reviewers. Please try and make this section as extensive as
possible by putting on paper all of your various experiences with the technique. Each ‘Note’
should be cross-referenced with the ‘Materials’ and ‘Methods’ sections, e.g. (see Note 1).

* Sources of failure:

    * bad optimizer, bad data or bad loss function
  
    * bug in coding ( permuting the data )

---- performance relative to other methods - esp on older subjects

* Multiple models and voting if you want to win kaggle (538)

* Benchmark against atropos: Speed/performance

* Benchmark against KMeans: Speed/performance

* Benchmark against JLF: Speed/performance

* how do we "see" the results?

* tricks:
    
    * dropout
 
    * approaches to adding coordinate systems
    
    * data augmentation ( rigid, affine, elastic )
    
    * L0/L1 regularization
    
    * hyperparameter optimization: more complex problems lead to greater parameter complexity
    
    * avoid overfitting (e.g. early termination)
    
    * find better or more data ( may meet limits of human performance )
    
    * batch optimization parameters wrt GPU or CPU capacity
    
    * issue: mismatch of test and validation data
    
    * issue: unknown nuisance parameters
    
    * issue: balanced sampling of classification sets ( randomized, class-specific, etc - avoid dominance by a single class )

    * see kaggle forums for additional details

    * 
# References

Arabic numbers should be used for text citations (set within parentheses at point of citation), and they should be listed in numerical order in text, as well as in the reference section. Please be as comprehensive as possible with the references.

